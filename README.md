# ⚡️FFPA: Faster  Flash Prefill Attention  
⚡️ FFPA: [F]aster [F]lash [P]refill [A]ttention with **O(1) SRAM complexity** & **O(d/4) register complexity** for large head dim (D > 256), almost **1.2x-1.5x** 🎉 faster than SDPA EA with MMA acc F32/F16 (Experimental 👀~).
